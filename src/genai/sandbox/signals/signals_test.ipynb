{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = \"gpt-4-1106-preview\"\n",
    "temperature=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karlis.kanders/Documents/code/discovery_generative_ai/.venv/lib/python3.9/site-packages/pinecone/index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from genai.eyfs import (\n",
    "    TextGenerator,\n",
    ")\n",
    "from genai import MessageTemplate, FunctionTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl(path: str) -> list:\n",
    "    \"\"\"Read a JSONL file.\"\"\"\n",
    "    with open(path, \"r\") as f:\n",
    "        return [json.loads(line) for line in f.readlines()]\n",
    "    \n",
    "def generate_signals_texts(signals_data: dict, chosen_signals: list = None):\n",
    "    signals = [signal[\"short_name\"] for signal in signals_data]\n",
    "    signals_titles = [signal[\"title\"] for signal in signals_data]\n",
    "    signals_summaries = [signal[\"summary\"] for signal in signals_data]\n",
    "\n",
    "    if chosen_signals is None:\n",
    "        chosen_signals = signals\n",
    "\n",
    "    # Combine titles and summaries into a single string\n",
    "    signals_description = \"\"\n",
    "    for short_name, title, summary in zip(signals, signals_titles, signals_summaries):\n",
    "        if short_name in chosen_signals:\n",
    "            signals_description += f\"Signal '{short_name}': {title}\\n{summary}\\n\\n\"\n",
    "\n",
    "    return signals_description    \n",
    "\n",
    "def generate_action_texts(action_data: dict):\n",
    "    actions = [a[\"name\"] for a in action_data]\n",
    "    action_descriptions = [a[\"description\"] for a in action_data]\n",
    "    action_text = \"\"\n",
    "    for name, description in zip(actions, action_descriptions):\n",
    "        action_text += f\"Action '{name}': {description}\\n\\n\"\n",
    "    return action_text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_signals_data = \"data/signals_2023.json\"\n",
    "signals_data = json.load(open(path_signals_data, \"r\"))\n",
    "signals_dict = {s['short_name']: s for s in signals_data}\n",
    "signals_descriptions = generate_signals_texts(signals_data) \n",
    "signals = [s['short_name'] for s in signals_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_actions_data = \"data/intent_actions.json\"\n",
    "actions_data = json.load(open(path_actions_data, \"r\"))\n",
    "actions_descriptions = generate_action_texts(actions_data)\n",
    "actions = [a['name'] for a in actions_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top signal prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_func_top_signal = \"data/func_top_signal.json\"\n",
    "path_prompt_top_signal = \"data/prompt_top_signal.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'predict_top_signal',\n",
       " 'description': 'Predict which of the signals are most relevant to user input',\n",
       " 'parameters': {'type': 'object',\n",
       "  'properties': {'prediction': {'type': 'string',\n",
       "    'enum': ['robochefs', 'abundant_energy'],\n",
       "    'description': 'The predicted most relevant signal'}},\n",
       "  'required': ['prediction']}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_top_signal = json.loads(open(path_func_top_signal).read())\n",
    "func_top_signal['parameters']['properties']['prediction']['enum'] = signals\n",
    "func_top_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': '###Instructions### Predict which of the following future signals is the most relevant to user input.\\n\\n###Future signal summaries###\\n{signals}\\n\\n###User input:\\n{user_input}'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_top_signal = read_jsonl(path_prompt_top_signal)\n",
    "prompt_top_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"I'm living in country side\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = MessageTemplate.load(path_prompt_top_signal)\n",
    "function = FunctionTemplate.load(func_top_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = TextGenerator.generate(\n",
    "        model=selected_model,\n",
    "        temperature=temperature,\n",
    "        messages=[message],\n",
    "        message_kwargs={\"signals\": signals_descriptions, \"user_input\": user_input},\n",
    "        stream=False,\n",
    "        functions=[function.to_prompt()],\n",
    "        function_call={\"name\": \"predict_top_signal\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x11b379770> JSON: {\n",
       "  \"role\": \"assistant\",\n",
       "  \"content\": null,\n",
       "  \"function_call\": {\n",
       "    \"name\": \"predict_top_signal\",\n",
       "    \"arguments\": \"{\\n\\\"prediction\\\": \\\"abundant_energy\\\"\\n}\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['choices'][0]['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': 'abundant_energy'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = json.loads(response['choices'][0]['message']['function_call']['arguments'])\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 3 signals prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_func_top_signals = \"data/func_top_three_signals.json\"\n",
    "path_prompt_top_signals = \"data/prompt_top_three_signals.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_top_signals = json.loads(open(path_func_top_signals).read())\n",
    "func_top_signals['parameters']['properties']['prediction']['items']['enum'] = signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': '###Instructions### Predict which three of the following future signals are the most relevant to user input. You have to choose three of these signals. \\n\\n###Future signal summaries###\\n{signals}\\n\\n###User input:\\n{user_input}'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_top_signals = read_jsonl(path_prompt_top_signals)\n",
    "prompt_top_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = MessageTemplate.load(path_prompt_top_signals)\n",
    "function = FunctionTemplate.load(func_top_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"I am a parent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = TextGenerator.generate(\n",
    "        model=selected_model,\n",
    "        temperature=temperature,\n",
    "        messages=[message],\n",
    "        message_kwargs={\"signals\": signals_descriptions, \"user_input\": user_input},\n",
    "        stream=False,\n",
    "        functions=[function.to_prompt()],\n",
    "        function_call={\"name\": \"predict_top_signals\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': ['Pronatalism vs pro-family',\n",
       "  'Hidden Figures',\n",
       "  'Green neighbours']}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = json.loads(response['choices'][0]['message']['function_call']['arguments'])\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pronatalism vs pro-family', 'Hidden Figures', 'Green neighbours']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer['prediction'][0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intent detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_func_intent = \"data/func_intent.json\"\n",
    "path_prompt_intent = \"data/prompt_intent.jsonl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'predict_intent',\n",
       " 'description': \"Predict what is the user's intent\",\n",
       " 'parameters': {'type': 'object',\n",
       "  'properties': {'prediction': {'type': 'string',\n",
       "    'enum': ['one_specific_signal', 'more_signals', 'following_up'],\n",
       "    'description': 'The predicted intent'}},\n",
       "  'required': ['prediction']}}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_intent = json.loads(open(path_func_intent).read())\n",
    "func_intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'You are a helpful chatbot talking with the user about the future signals. ###Instructions### Predict the intended action of the user, what the user wishes you to carry out based on the user input\\n\\n###Possible intents###\\n{intents}\\n\\n###User input:\\n{user_input}'}]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_intent = read_jsonl(path_prompt_intent)\n",
    "prompt_intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = MessageTemplate.load(path_prompt_intent)\n",
    "function = FunctionTemplate.load(func_intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"Tell me about the robot chef\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = TextGenerator.generate(\n",
    "        model=selected_model,\n",
    "        temperature=temperature,\n",
    "        messages=[message],\n",
    "        message_kwargs={\"intents\": actions_descriptions, \"user_input\": user_input},\n",
    "        stream=False,\n",
    "        functions=[function.to_prompt()],\n",
    "        function_call={\"name\": \"predict_intent\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': 'one_specific_signal'}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = json.loads(response['choices'][0]['message']['function_call']['arguments'])\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt: Impact on the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_prompt = \"data/02_signal_impact.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = \"robochefs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = MessageTemplate.load(path_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"I like food\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = TextGenerator.generate(\n",
    "        model=selected_model,\n",
    "        temperature=temperature,\n",
    "        messages=[message],\n",
    "        message_kwargs={\n",
    "            \"signal\": signals_dict[signal]['full_text'], \n",
    "            \"user_input\": user_input\n",
    "            },\n",
    "        stream=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The future signal about robochefs and automation in commercial kitchens might be relevant to you as someone who likes food because it explores the potential impact of this technology on our diets and the food industry. \n",
      "\n",
      "Three ways this future signal might impact you are: \n",
      "1. It could lead to the automation of food preparation and distribution, making meals faster and potentially cheaper.\n",
      "2. There might be a relative reduction in the price of fast food compared to healthier options if innovation is primarily focused on mass production.\n",
      "3. However, there is also potential for healthier processes and options to be developed, such as using air frying instead of deep frying, and chains specializing in healthier food getting involved in kitchen robotics.\n",
      "\n",
      "If you have any questions about how this technology might impact the food industry or your own food choices, feel free to ask. Alternatively, you can also ask about other future signals that interest you.\n"
     ]
    }
   ],
   "source": [
    "answer = response['choices'][0]['message']['content']\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt: Summary of different signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_prompt = \"data/03_signal_choice.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_signals = [\"robochefs\", \"baby_boom\", \"abundant_energy\"]\n",
    "signals_text = generate_signals_texts(signals_data, chosen_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = MessageTemplate.load(path_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"I like food\"\n",
    "message_history = [\n",
    "    MessageTemplate.load({\"role\": \"user\", \"content\": \"I'm a parent\"}),\n",
    "    MessageTemplate.load({\"role\": \"user\", \"content\": \"I have a heat pump\"}),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MessageTemplate(initial_template={'role': 'user', 'content': \"I'm a parent\", 'name': None}, role='user', content=\"I'm a parent\", name=None),\n",
       " MessageTemplate(initial_template={'role': 'user', 'content': 'I have a heat pump', 'name': None}, role='user', content='I have a heat pump', name=None),\n",
       " MessageTemplate(initial_template={'role': 'user', 'content': 'Start your answer by explaining each of the signals in one clear sentence (use similar language to the signals descriptions). If possible, indicate how a signal might be relevant to the user, given the user information and conversation history. Finish your answer by asking the user to choose one of the signals to hear more about it. Remember that you must be patient and never offend or be aggressive.   \\n\\n###Future signals###{signals}\\n\\n###User information### Here is what the user told you about themselves: {user_input}.\\n\\n###Answer###', 'name': None}, role='user', content=\"Start your answer by explaining each of the signals in one clear sentence (use similar language to the signals descriptions). If possible, indicate how a signal might be relevant to the user, given the user information and conversation history. Finish your answer by asking the user to choose one of the signals to hear more about it. Remember that you must be patient and never offend or be aggressive.   \\n\\n###Future signals###Signal 'robochefs': Robochefs: a bumpy road from lab to kitchen?\\nThe signal discusses the impact of automation in commercial kitchens, suggesting that redirecting research and development towards healthier processes, like air frying, could benefit our diets. Companies like Sweetgreen and YPC Technologies are innovating in this space, with initiatives like “cooking as a service” using fresh ingredients. However, the sector faces challenges due to a downturn in venture capital investment, leading to shutdowns of several kitchen robotics start-ups, indicating a need for further refinement in their value propositions.\\n\\nSignal 'abundant_energy': Too cheap to meter: could low-cost renewables create an abundance of energy?\\nThe article highlights the significant decrease in costs for solar and wind power, offering hope for a new era of abundant, clean energy despite the current energy crisis. It discusses the challenges of energy intermittency with renewables and suggests overproducing energy to compensate, enabling opportunities for storage and flexible use. Additionally, it explores the potential for using excess renewable energy in innovative ways, like green desalination and direct air capture for carbon removal, while cautioning against potential environmental impacts and overconsumption.\\n\\nSignal 'baby_boom': Baby boom: pronatalism vs pro-family\\nThe article discusses the rising political interest in pronatal policies, which aim to incentivize higher birth rates in response to declining fertility rates and the economic consequences of an aging population. While some countries have implemented measures like baby bonuses and tax cuts with varied success, these policies are often critiqued for their modest impact on long-term birth rates and potential implications for women's roles and anti-immigration sentiments. The article suggests that a more effective approach would be comprehensive pro-family policies focusing on childcare, parental leave, and overall family wellbeing, as seen in countries like Sweden, where such policies have been associated with relatively higher fertility rates.\\n\\n\\n\\n###User information### Here is what the user told you about themselves: I like food.\\n\\n###Answer###\", name=None)]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms = message_history + [message]\n",
    "ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = TextGenerator.generate(\n",
    "        model=selected_model,\n",
    "        temperature=temperature,\n",
    "        messages=ms,\n",
    "        message_kwargs={\n",
    "            \"signals\": signals_text, \n",
    "            \"user_input\": user_input\n",
    "            },\n",
    "        stream=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given your interest in food, you might find the signal 'robochefs' particularly relevant as it discusses the intersection of technology and culinary practices. Robochefs are a new development where automation is being integrated into commercial kitchens, potentially influencing the way food is prepared and served. Companies are exploring healthier cooking methods and fresh ingredients, but the industry is facing economic challenges with a need for clearer benefits to attract investment.\n",
      "\n",
      "The signal 'abundant_energy' could be interesting to you as a parent and homeowner with a heat pump, because it talks about the future of energy sources, like solar and wind power, which could affect how you power your home and devices, including heating and cooling systems. The article touches on the possibility of energy becoming more affordable and abundant, which can lead to innovative uses and impact environmental sustainability.\n",
      "\n",
      "Lastly, the signal 'baby_boom' touches on societal trends and policies that may affect you as a parent. It discusses how governments are responding to changing birth rates with policies that could influence family life, such as childcare support and parental leave. This could be of interest to you in understanding the broader context of family wellbeing and the support you might expect from societal structures.\n",
      "\n",
      "Would you like to hear more about how robochefs could change the future of cooking and food preparation, the potential for an energy-rich future with renewables that could impact your heat pump usage, or the societal and policy implications of pronatalism and pro-family approaches? Please let me know which topic you'd like to explore further.\n"
     ]
    }
   ],
   "source": [
    "answer = response['choices'][0]['message']['content']\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
